<div align = 'center'><font size = 50> A Brief Description of the Google File System </font> </div>

<center> 18301151 朱书勤 </ccenter>

# ABSTRACT
The Google File System is a scalable distributed file system for large distributed data-intensive applications. Comparing with other distributed file systems like HDFS, TFS, and Haystack, GFS focus mutate appending new data rather than overwrite new data to huge files.

In this paper, I will mainly discuss the difference between GFS and HDFS,the Consistency, Availability, Partition tolerance of the GFS, and it's advantages & disadvantages.

# INTRODUCTION
The Google File System(GFS) was meant to be built on ordinary, cheap machines, which means failures are normal rather than accidents. And it was designed to meet certain demands :

* The system hopes to store a large number of large size single files.
* The system supports two types of read operations: large streaming reads and small random reads.
* The write operation of the system is mainly sequential appending write, not overwriting new data.
* The system has a lot of optimizations for concurrent append writing of a large number of clients to ensure the efficiency and consistency of writing.（The atomic operation record append must be assured.）
* The system pays more attention to the continuous and stable bandwidth rather than the delay of a single read and write.

The GFS system is composed of three parts: GFS master, GFS Client, and GFS chunk server. There must be one and only one master at any time, while there may be multiple chunk servers and clients. A file is divided into multiple fixed-size chunks (default 64M), each chunk has a globally unique file handle-a 64-bit chunk ID, each chunk will be copied to multiple chunk servers (default value is 3) to ensure availability and reliability. The chunk server stores chunks on local disks as ordinary Linux files. The GFS master is the metadata server of the system. The metadata maintained includes: command space (GFS manages files according to hierarchical directories), file-to-chunk mapping, and chunk location. Among them, the first two will be persistent, and the location information of the chunk comes from the report of the chunk server. The GFS master is also responsible for the centralized scheduling of distributed systems: chunk lease management, garbage collection, chunk migration and other important system controls. Similar to the HDFS, the master and chunk servers maintain a regular heartbeat to determine the state of chunk servers. The GFS client is an API for applications. 

# DIFFERENCE 	

In the GFS, data stream and control stream are separated, in order to meet the demands of maximize the use of each machine's network bandwidth, avoid network bottlenecks and high-latency connections, and minimize push delays. 

On of the common methods is the master-slave mode: The client first pushes the data to the primary, and then the primary pushes to all secondary. Obviously, the pressure on Primary will be great. In GFS, since it's purpose is to maximize the balanced utilization of network bandwidth, this is not suitable. Moreover, both the client and the replica know which node is closer to them, so they can choose the best path. Therefor, the GFS uses TCP connection to deliver data stream to minimize latency. Once the chunk server receives the data, it immediately starts pushing, that is, a replica does not need to receive the complete data before sending it to the next replica. Once the data is written to the temporary buffer, the control message is needed to actually take effect. The client will notify Primary the submitting. After the Primary submits successfully, it will notify all Secondary to submit. And after it received responds from all Secondary, the Primary will reply client submit result. This means the writing of control messages is synchronous in GFS, which guarantees the consistency of the data between the copies, so data can be read from any copy when it can be read.

## HDFS

GFS and HDFS are very different in the design of key points. HDFS has made many simplifications in order to avoid the complexity of GFS

First of all, the most complicated part of GFS is to append the same file to multiple clients concurrently, that is, the multi-client concurrent Append model. GFS allows files to be opened multiple times or by multiple clients at the same time to append data, in record units. Assuming that the size of GFS additional records is between 16KB ~ 16MB, the average size is 1MB. It is obviously inefficient to access the GFS Master every time it is added. Therefore, GFS grants the write permission of each Chunk to the Chunk Server through the Lease mechanism. The meaning of writing a Lease is that the Chunk Server has write permission for a certain Chunk within the Lease validity period (assuming 12s). The Chunk Server that owns the Lease is called the Primary Chunk Server. If the Primary Chunk Server is down, the Chunk can write Lease after the Lease validity period. Assign to other Chunk Server. Multiple clients concurrently append the same file, causing Chunk Server to sequence the records. After the client's write operation fails, it may be retried, resulting in duplicate records. In addition, the client API is an asynchronous model, which causes the record disorder problem. . Under the Append model, problems such as duplicate records and disorder, plus the Lease mechanism, especially the Lease of the same Chunk may migrate between Chunk Servers, which greatly increases the complexity of the system design and consistency model. In HDFS, HDFS files are only allowed to be opened and appended to data once. The client writes all data to a local temporary file first, and waits until the data volume reaches the size of a Chunk (usually 64MB), and requests the HDFS Master to allocate a work machine and Chunk number, write one Chunk data into HDFS file at one time. Since 64MB of data is accumulated to actually write to the HDFS system, there is little pressure on the HDFS Master, and there is no need for a mechanism similar to GFS to authorize write Lease to the working machine, and there is no duplication of records and disorder, which greatly simplifies The design of the system. However, we must know that HDFS does not support many problems caused by the Append model. Hypertable and HBase built on HDFS need to use HDFS to store the operation logs of the table system, because the HDFS client needs to save up to 64MB of data. When writing to HDFS, if the table service node in Hypertable and HBase (corresponding to the Tablet Server in Bigtable) is down, some operation logs are not written to HDFS, and data may be lost.

The second is the handling of Master single point failure. GFS adopts the master-slave mode to back up the system metadata of the Master. When the master master fails, it can continue to provide services to the outside world through the distributed election of the standby machine. However, due to the complexity of the replication and the master-slave switch, the HDFS Master Persistent data is only written to the local machine (multiple copies may be written to multiple disks stored in the Master machine to prevent damage to a certain disk), and manual intervention is required when a failure occurs. Another point is the support for snapshots. GFS uses internal copy-on-write data structure to realize cluster snapshot function, while HDFS does not provide snapshot function. In a large-scale distributed system, it is normal for the program to have bugs. Although the bugs can be fixed in most cases, it is difficult to restore the system data to a consistent state through compensation operations. The underlying system often needs to provide a snapshot function. The system is restored to a recent consistent state.

GFS garbage collection uses a lazy recycling strategy, that is, the master does not immediately reclaim file resources deleted by the program. GFS chooses to mark deleted files in a specific form (usually by changing the file name to a hidden name containing time information) so that such files are no longer accessed by ordinary users. The Master will periodically check the file name space and delete hidden files some time ago. HDFS does not adopt such a garbage collection mechanism, but adopts a simpler but easier to implement direct deletion method. Both methods have their own advantages. Delayed collection gives users a rollback operation. At the same time, the specific operation of recycling resources is completed when the Master node is idle, which greatly improves the performance of GFS. However, delayed recovery will take up a large amount of storage space, and there are major performance problems when faced with a large number of file creation and deletion, which cannot satisfy users' vicious operations.

In a word, HDFS was born from GFS, but is more likely to be a simplified version of the GFS. However, due to the community support caused by its opening source, the HDFS has a wider use in the industry then GFS.

#  CAP
In the NoSQL class, we learned about the CAP(Consistency, Availability, Partition tolerance) principle. The GFS mainly focus on Availability and Partition tolerance with a relatively weak Consistency.

To insure its high availability,  The Master will persist the cluster metadata in the form of writing Operation Log first: Before the log is actually been written, the Master will not respond to the client's request, and subsequent changes will not continue to be executed; except, the log It will also be backed up to multiple other machines, and the log will only be deemed to have been written out when it is written to the persistent storage of local and remote backups. When restarting, the Master will restore its own state by replaying the saved operation records. In order to ensure that the Master can complete the recovery quickly, the Master will create a checkpoint for its current state after the log reaches a certain size, and delete the previous log created by the Checkpoint. When restarting, it will start to recover from the most recently created Checkpoint. The content of the Checkpoint file will be organized in the form of a B-tree, and after being mapped to the memory, the stored Namespace can be retrieved without other additional parsing operations, which further reduces the Master recovery required time. In order to simplify the design, only one Master is active at the same time. When the Master fails, the external monitoring system will detect this event and restart the new Master process elsewhere. In addition, there will be other shadow masters in the cluster that provide read-only functions: they will synchronize the master's state changes, but there may be a delay of several seconds, and they are mainly used to share the pressure of read operations for the master. The Shadow Master will synchronize its state with the Master by reading a backup of the Master's operation log; it will also poll the Chunk Servers at startup like the Master, learn the Chunk Replica information they hold, and continue Monitor their status. In fact, after the Master fails, the Shadow Master can still provide read-only functions for the entire GFS cluster, and the Shadow Master's dependence on the Master is limited to the update event of the Replica location. As the role of Slave in the cluster, Chunk Server has a much higher probability of failure than the Master. When it fails, the number of Replicas of the Chunk corresponding to the Replica held by it will decrease, and the Master will also find that the number of Replicas is lower than the threshold specified by the user and schedule a re-backup. In addition, when the Chunk Server fails, the user's write operation will continue. Then when the Chunk Server restarts, the Replica data on the Chunk Server may have expired. For this reason, the Master maintains a version number for each Chunk to distinguish between normal and expired replicas. Whenever the Master assigns Chunk Lease to a Chunk Server, the Master will increase the version number of the Chunk and notify the other latest replicas to update its version number. If a Chunk Server fails at this time, the version number of the Replica on it will not change. When Chunk Server restarts, Chunk Server will report to the Master its Chunk Replica and the corresponding version number. If the Master finds that the version number of a certain Replica is too low, it will think that the Replica does not exist, so the expired Replica will be removed during the next Replica recycling process. In addition, when the Master returns the Replica location information to the client, it will also return the current version number of the Chunk, so that the client will not read the old data.

In order to make sure the data stored in GFS is complete and the system has the ability for Partition tolerance, each Chunk will be backed up in a different Chunk Server in the form of Replica, and users can assign different backup strategies to different parts of the Namespace. In order to ensure the integrity of the data, each Chunk Server will check whether its saved data is damaged in the form of checksum; after detecting damaged data, the Chunk Server can also use other replicas to recover the data. First, Chunk Server will divide each Chunk Replica into several 64KB blocks, and calculate a 32-bit checksum for each block. Like the metadata of the Master, these checksums will be stored in the memory of the Chunk Server, and will be written to the log before each oddification to ensure availability. When Chunk Server receives a read request, Chunk Server first uses a checksum to check whether the data that needs to be read is damaged, so that Chunk Server will not pass the damaged data to the request senders, regardless of it Is it the client or another Chunk Server. After the damage is found, the Chunk Server will send an error to the request sender and notify the Master of the data corruption event. After receiving the error, the request sender will select another Chunk Server to re-initiate the request, and the Master will use another Replica to re-backup the Chunk. When the new Replica is created, the Master will notify the Chunk Server to delete the damaged Replica. When performing data append operations, Chunk Server can incrementally update the checksum of the checksum block at the end of the Chunk, or calculate a new checksum when a new checksum block is generated. . Even if the added checksum block has suffered data damage before, the incrementally updated checksum will still not match the actual data, and the data damage can still be detected in the next read. During the data writing operation, the Chunk Server must read and verify the checksum block containing the start and end points of the writing range, then write it, and finally recalculate the checksum. In addition, when idle, Chunk Server will periodically scan and verify the data of inactive Chunk Replicas to ensure that some Chunk Replicas can still be detected for data corruption even when they are not read much. At the same time, it also ensures that these damaged Chunk Replicas will not let the Master think that the Chunk has a sufficient number of Replicas. The components of GFS are designed to increase the speed of state recovery, which can usually be started within a few seconds. Under this guarantee, GFS components actually do not distinguish between normal shutdown and abnormal exit. But, if the Master gone offline, the system will respond accordingly to solve the problem. In the GFS cluster, there will be a Replica Master holding a complete backup of the Master state; through a specific mechanism, GFS will switch to one of the Replicas when the Master fails. It is possible that this will require the intervention of a human manager to designate a new Master. In any case, we can determine that there is a single point of failure lurking in the cluster, which can theoretically prevent the cluster from automatically recovering from the failure of the Master.

The GFS defines the following types of consistency:
* Defined: 
The state is defined. From the perspective of the client, the client fully understands the data that has been written to the cluster. That is, when a client writes a file, whether it can read the file written before, that is, whether it is consistent with its own writing.

* Consistent: 
The client sees that the data of multiple copies of the chunk is completely consistent, but not necessarily defined.

* Inconsistent: 
 Multiple copies of data are inconsistent.

* Undefined: 
The data is undefined.

The GFS provides an atomic append operation, that is, the Client only needs to specify the data to be written without specifying the offset value, and system guarantees that at least one atomic write operation is executed successfully, and returns the start of the successfully appended data. The offset value of the starting position is given to the Client. The introduction of record appending is to reduce the overhead of the synchronization mechanism that many Clients write to the same data in parallel in distributed applications, such as using a distributed lock manager. The write operation will be performed on all copies. Whether it is a serial write or a parallel write, once it fails, the data on multiple chunk copies may be inconsistent. Secondly, the data read by the client from different copies is different (some copies may succeed but some copies Failure), therefore, must also be undefined and inconsistent. For append operations, the client does not need to specify the offset. The master copy of the chunk decides to write the offset according to the current file size. After the write is successful, the offset is returned to the client. Therefore, the client can know the write result according to the offset, regardless of Whether it is serial writing or concurrent writing, its behavior is defined. If the append fails for the first time, the data in the 10-60 multiple copies may be inconsistent, but the next retry succeeds. The data from 60 to 110 is consistent. Therefore, its status is interspersed with inconsistent, which means it has a partial inconsistent.

When a file is being deleted by a user, GFS does not immediately delete the data, but lazyly removes the data at both the file and Chunk levels. First, when a user deletes a file, GFS will not directly remove the record of the file from the Namespace, but will rename the file to another hidden name with the time stamp of when it was deleted. When the Master periodically scans the Namespace, it will find those files that have been deleted for a long time, and then the Master will actually remove them from the Namespace. Before the file is completely deleted from the Namespace, the client can still use the renamed hidden name to read the file, or even rename it again to undo the delete operation. The Master maintains the mapping between files and Chunks in the metadata: when the files in the Namespace are removed, the reference count of the corresponding Chunk is automatically decremented by 1. Also in the process of the Master periodically scanning the metadata, the Master will find Chunks whose reference count has been 0. At this time, the Master will remove the metadata related to these Chunks from its own memory. In the periodic heartbeat communication between the Chunk Server and the Master, the Chunk Server will report the Chunk Replica it holds. At this time, the Master will tell the Chunk Server which Chunk no longer exists in the metadata, and the Chunk Server can remove the corresponding Replica.

# ADVANTAGES & DISADVANTAGES

GFS sacrifices correctness for performance and simplicity. Ensuring strong consistency usually requires more complex protocols that require more communication between machines. By taking advantage of the fact that certain types of applications can tolerate looser consistency, one can design a system with good performance and sufficient consistency. GFS has made special optimizations for MapReduce applications. These applications require high reading efficiency for large files, and can tolerate data holes, duplicate records, or inconsistent reading results in files; on the other hand, GFS does not Suitable for storing information with extremely high requirements for consistency.

## ADVANTAGES

* High performance 
* High availability

* The cost of increasing the memory capacity of the Master is much smaller.
The metadata stored in the memory of the Master makes it extremely easy for the Master to make changes to the metadata; at the same time, it also enables the Master to scan the cluster metadata more efficiently to evoke system-level management operations such as Chunk recycling and Chunk balancing. . The only shortcoming is that this makes the number of Chunks that the entire cluster can have is limited to the memory size of the Master, but from the content of the paper, such a bottleneck has never been touched in Google, which stems from a 64MB Chunk , Master only needs to maintain less than 64 bytes of metadata. 


For distributed file system, the size of the Chunk is an important parameter, and GFS chose to use 64MB as the size of the Chunk. Larger Chunk mainly brings the following benefits: reduce the frequency of communication between the client and the Master, increase the probability that these operations fall on the same Chunk when the client performs operations, and reduce the volume of metadata to be saved by the Master.

* For large-scale distributed systems, GFS's file deletion mechanism is more reliable.
When a Chunk is created, the creation operation may succeed on some Chunk Servers, and fail on other Chunk Servers, which leads to some Chunk Servers. There may be replicas that the Master does not know about. In addition, the request to delete the Replica may fail to be sent, and the Master will need to remember to try to resend it. In contrast, Chunk Server actively deletes Replica to solve the above problems in a more unified way.
* Reduce resource consumption. 
The deletion mechanism combines the storage recovery process with the Master’s daily periodic scanning process. This allows these operations to be processed in batches to reduce resource consumption. In addition, this also allows the Master to choose relatively idle Time to perform these operations.
* Avoids the problem of user miss-operation. 
The delay between the user sending the deletion request and the actual deletion of the data also effectively make sure of this.

The Master adopt a strategy in selecting the location of Replica, it is not only  stored on different machines, but also on different racks, so that if the entire rack is unavailable, the data can still survive. In this way, different clients can use the export bandwidth of different racks when reading the same Chunk. Master's Replica orchestration strategy achieved two goals: 
* Maximize data availability
* Maximize network bandwidth utilization.

## Disadvantages

* Storage overhead. 
GFS's delete mechanism hinders users from tuning storage space usage, especially when storage space is scarce.
*  Data will flow between different racks when writing.
However, from the original intention of the system design, this is a reasonable trade-off.

The consistency model of GFS is relatively loose, which requires upper-layer applications to adapt to the consistency semantics provided by GFS when using GFS. The upper application can do this in two ways: more use of append operations rather than overwrite operations; and write data that contains verification information. The reason for favoring append operations over overwrite operations is obvious: GFS has made significant optimizations for append operations, which makes this data writing method more performant and also provides stronger consistency semantics. Nevertheless, the at least once feature of the append operation still makes it possible for the client to read padding or duplicate data, which requires the client to tolerate this invalid data. A feasible approach is to write their own checksums for all records at the same time as writing, and check when reading to eliminate invalid data; if the client cannot tolerate duplicate data, the client can also Write a unique identifier for each record when writing, so that the identifier can remove duplicate data when reading.

There are still many other disadvantages in the system. However, as was said previously, in order to meet the initial demands of the GFS, reasonable trade-offs will be made and are acceptable.

# CONCLUSSIONS

The design of GFS is highly worth learning. The target files and file operations supported by the system are very clear and simple. How to build a stable system on a data center composed of large-scale unstable PCs, use replication for data, and use algorithms such as Paxos for metadata. This file system embodies the trade off options of other parties in a fairly high-level system design.